
# COMPAS Dataset Bias Audit with AI Fairness 360

## 1. Install Required Packages

```python
!pip install aif360 pandas matplotlib seaborn scikit-learn
```

## 2. Import Libraries

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from aif360.datasets import CompasDataset
from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric
from aif360.algorithms.preprocessing import Reweighing
```

## 3. Load and Explore Dataset

```python
dataset = CompasDataset()
dataset.features.head()
```

## 4. Define Privileged and Unprivileged Groups

```python
privileged_groups = [{'race': 1}]   # Caucasian
unprivileged_groups = [{'race': 0}] # African-American
```

## 5. Evaluate Bias Metrics

```python
binary_metrics = BinaryLabelDatasetMetric(dataset,
                                          privileged_groups=privileged_groups,
                                          unprivileged_groups=unprivileged_groups)

print("Disparate Impact:", binary_metrics.disparate_impact())
print("Mean Difference:", binary_metrics.mean_difference())
```

## 6. Classification Metrics (False Positive Rate)

```python
classified_metrics = ClassificationMetric(dataset, dataset,
                                          privileged_groups=privileged_groups,
                                          unprivileged_groups=unprivileged_groups)

fpr_privileged = classified_metrics.false_positive_rate(privileged=True)
fpr_unprivileged = classified_metrics.false_positive_rate(privileged=False)

print("FPR Privileged:", fpr_privileged)
print("FPR Unprivileged:", fpr_unprivileged)
```

## 7. Visualize False Positive Rates

```python
sns.barplot(x=['Privileged', 'Unprivileged'], 
            y=[fpr_privileged, fpr_unprivileged], 
            palette='pastel')
plt.title('False Positive Rate by Race')
plt.ylabel('False Positive Rate')
plt.tight_layout()
plt.show()
```

## 8. Optional: Apply Reweighing for Fairness Mitigation

```python
RW = Reweighing(unprivileged_groups=unprivileged_groups,
                privileged_groups=privileged_groups)
dataset_transf = RW.fit_transform(dataset)
```

## 9. Rerun Bias Metrics on Mitigated Dataset

```python
binary_metrics_rw = BinaryLabelDatasetMetric(dataset_transf,
                                             privileged_groups=privileged_groups,
                                             unprivileged_groups=unprivileged_groups)
print("Post-Mitigation Disparate Impact:", binary_metrics_rw.disparate_impact())
print("Post-Mitigation Mean Difference:", binary_metrics_rw.mean_difference())
```

